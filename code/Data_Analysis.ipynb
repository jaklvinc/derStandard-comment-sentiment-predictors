{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e746fa8",
   "metadata": {},
   "source": [
    "# Analysis of Effects from Artilces of Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kruskal\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a79cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set format to float with 4 decimals\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7684038",
   "metadata": {},
   "source": [
    "Load, specify and visualize data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "sentiments = pd.read_csv(\"sentiment_results.csv\")\n",
    "\n",
    "#emotions of articles(_A) and posts(_P) included in the analysis \n",
    "emotions_a = ['Anger_A', 'Fear_A', 'Disgust_A', 'Joy_A', 'None_A']\n",
    "emotions_p = ['Anger_P', 'Fear_P', 'Disgust_P', 'Joy_P', 'None_P']\n",
    "\n",
    "#filter relevant colums\n",
    "sentiments = sentiments[emotions_a + ['NewsroomTopic'] + emotions_p]\n",
    "\n",
    "#visualize distribution of predictors\n",
    "sentiments[emotions_a].hist(bins=30, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f462ed",
   "metadata": {},
   "source": [
    "Set Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547e5dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set for optimal cpu utilisation\n",
    "parallel_jobs = 10\n",
    "\n",
    "#settings to account for testing errors\n",
    "alpha = 0.05\n",
    "bootstrap_samples = 10000\n",
    "\n",
    "#ranking parameters for emotions in articles\n",
    "between_ranks = 2\n",
    "rank_threshold = 1/6\n",
    "\n",
    "#set seed for reproducibility\n",
    "seed = 666"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198d848",
   "metadata": {},
   "source": [
    "Precompute Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12358054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare topics\n",
    "sentiments['NewsroomTopic'] = sentiments['NewsroomTopic'].astype('category')\n",
    "topics = sentiments['NewsroomTopic'].to_numpy()\n",
    "topic_levels = sentiments['NewsroomTopic'].cat.categories.to_numpy()\n",
    "\n",
    "\n",
    "#convert DV arrays for faster access\n",
    "dv_arrays = {dv: sentiments[dv].to_numpy() for dv in emotions_p}\n",
    "\n",
    "#generate seed based bootstrap indices for tests\n",
    "rng = np.random.default_rng(seed)\n",
    "n = len(sentiments)\n",
    "\n",
    "bootstrap_indices = []\n",
    "for i in range(bootstrap_samples):\n",
    "    idx = rng.choice(n, size=n, replace=True)\n",
    "    bootstrap_indices.append(idx)\n",
    "\n",
    "#build dicts to store bootstrap stats\n",
    "boot_pvalues_dict = {}\n",
    "boot_epsilon_dict = {}\n",
    "boot_k_dict = {}\n",
    "boot_desc_means_dict = {}\n",
    "boot_desc_stds_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5602a",
   "metadata": {},
   "source": [
    "Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33707152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal_test(groups):\n",
    "\n",
    "    clean_groups = [g for g in groups if len(g) > 0]\n",
    "\n",
    "    if len(clean_groups) <= 1:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    H, p = kruskal(*clean_groups)\n",
    "    k = len(clean_groups)\n",
    "    n_total = sum(len(g) for g in clean_groups)\n",
    "    epsilon = (H - k + 1) / (n_total - k) if n_total > k else np.nan\n",
    "\n",
    "    return H, p, epsilon, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7e8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_stats(H_list, epsilon_list, p_list, k_list):\n",
    "    \n",
    "    H_arr = np.array(H_list)\n",
    "    eps_arr = np.array(epsilon_list)\n",
    "    p_arr = np.array(p_list)\n",
    "    k_arr = np.array(k_list)\n",
    "    \n",
    "    return {\n",
    "        \"H_mean\": np.nanmean(H_arr),\n",
    "        \"epsilon2_mean\": np.nanmean(eps_arr),\n",
    "        \"epsilon2_ci_lower\": np.nanpercentile(eps_arr, 100 * alpha / 2),\n",
    "        \"epsilon2_ci_upper\": np.nanpercentile(eps_arr, 100 * (1 - alpha / 2)),\n",
    "        \"mean_p_value\": np.nanmean(p_arr),\n",
    "        \"signif_prob\": np.mean(p_arr <= alpha) if len(p_arr) > 0 else np.nan,\n",
    "        \"mean_k\": np.nanmean(k_arr)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edd1c5",
   "metadata": {},
   "source": [
    "Analysis of Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c979712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_bootstrap(idx_list, dv, iv_emo):\n",
    "\n",
    "    H_vals, epsilon_vals, p_vals, k_vals = [], [], [], []\n",
    "    for idx in idx_list:\n",
    "        dv_data = dv_arrays[dv][idx]\n",
    "        iv_data = sentiments[iv_emo].to_numpy()[idx]\n",
    "        topic_data = topics[idx]\n",
    "        \n",
    "        num_ranks = between_ranks + 2 if rank_threshold > 0 else between_ranks\n",
    "        \n",
    "        if rank_threshold > 0:\n",
    "            edges = np.linspace(rank_threshold, 1 - rank_threshold, between_ranks + 1)\n",
    "            edges = np.concatenate([[0], edges, [1]])\n",
    "        else:\n",
    "            edges = np.linspace(0, 1, between_ranks + 1)\n",
    "        \n",
    "        edges = np.unique(edges)\n",
    "        rank_data = pd.cut(\n",
    "            iv_data,\n",
    "            bins=edges,\n",
    "            labels=False,\n",
    "            include_lowest=True,\n",
    "            duplicates='drop'\n",
    "        ) + 1\n",
    "        \n",
    "        for lvl in topic_levels:\n",
    "            mask = topic_data == lvl\n",
    "            groups = [dv_data[(mask) & (rank_data == r)] for r in range(1, len(edges))]\n",
    "            \n",
    "            H, p, epsilon, k = kruskal_test(groups)\n",
    "            \n",
    "            if not np.isnan(H):\n",
    "                H_vals.append(H)\n",
    "                epsilon_vals.append(epsilon)\n",
    "                p_vals.append(p)\n",
    "                k_vals.append(k)\n",
    "    \n",
    "    return {\"H\": H_vals, \"epsilon\": epsilon_vals, \"p\": p_vals, \"k\": k_vals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f129fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_parallel(dv, iv_emo):\n",
    "    \n",
    "    split_indices = np.array_split(bootstrap_indices, parallel_jobs)\n",
    "    results = Parallel(n_jobs=parallel_jobs)(\n",
    "        delayed(emotion_bootstrap)(sub_idx, dv, iv_emo) for sub_idx in split_indices\n",
    "    )\n",
    "\n",
    "    H_all, eps_all, p_all, k_all = [], [], [], []\n",
    "    for r in results:\n",
    "        H_all.extend(r[\"H\"])\n",
    "        eps_all.extend(r[\"epsilon\"])\n",
    "        p_all.extend(r[\"p\"])\n",
    "        k_all.extend(r[\"k\"])\n",
    "\n",
    "    boot_epsilon_dict[(dv, iv_emo)] = eps_all\n",
    "    boot_pvalues_dict[(dv, iv_emo)] = p_all\n",
    "    boot_k_dict[(dv, iv_emo)] = k_all\n",
    "\n",
    "    return bootstrap_stats(H_all, eps_all, p_all, k_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969c51c",
   "metadata": {},
   "source": [
    "Analysis of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9525c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_bootstrap(idx_list, dv):\n",
    "\n",
    "    H_vals, epsilon_vals, p_vals, k_vals = [], [], [], []\n",
    "    for idx in idx_list:\n",
    "        dv_data = dv_arrays[dv][idx]\n",
    "        topic_data = topics[idx]\n",
    "        groups = [dv_data[topic_data == lvl] for lvl in topic_levels]\n",
    "        H, p, epsilon, k = kruskal_test(groups)\n",
    "        \n",
    "        if not np.isnan(H):\n",
    "            H_vals.append(H)\n",
    "            epsilon_vals.append(epsilon)\n",
    "            p_vals.append(p)\n",
    "            k_vals.append(k)\n",
    "\n",
    "    return {\"H\": H_vals, \"epsilon\": epsilon_vals, \"p\": p_vals, \"k\": k_vals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce3fc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_parallel(dv):\n",
    "    \n",
    "    split_indices = np.array_split(bootstrap_indices, parallel_jobs)\n",
    "    results = Parallel(n_jobs=parallel_jobs)(\n",
    "        delayed(topic_bootstrap)(sub_idx, dv) for sub_idx in split_indices\n",
    "    )\n",
    "\n",
    "    H_all, eps_all, p_all, k_all = [], [], [], []\n",
    "    for r in results:\n",
    "        H_all.extend(r[\"H\"])\n",
    "        eps_all.extend(r[\"epsilon\"])\n",
    "        p_all.extend(r[\"p\"])\n",
    "        k_all.extend(r[\"k\"])\n",
    "\n",
    "    boot_epsilon_dict[(dv, \"NewsroomTopic\")] = eps_all\n",
    "    boot_pvalues_dict[(dv, \"NewsroomTopic\")] = p_all\n",
    "    boot_k_dict[(dv, \"NewsroomTopic\")] = k_all\n",
    "\n",
    "    return bootstrap_stats(H_all, eps_all, p_all, k_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659482d",
   "metadata": {},
   "source": [
    "Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "568e5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats():\n",
    "\n",
    "    numeric_vars = emotions_a + emotions_p\n",
    "    topics_arr = sentiments[\"NewsroomTopic\"].to_numpy()\n",
    "\n",
    "    rows = []\n",
    "    for var in numeric_vars:\n",
    "        x = sentiments[var].to_numpy()\n",
    "\n",
    "        for lvl in topic_levels:\n",
    "            topic_mask = topics_arr == lvl\n",
    "            data = x[topic_mask]\n",
    "\n",
    "            if data.size == 0:\n",
    "                continue\n",
    "\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data, ddof=1)\n",
    "            boot_means = np.empty(bootstrap_samples)\n",
    "\n",
    "            for b in range(bootstrap_samples):\n",
    "                sample_idx = bootstrap_indices[b]\n",
    "                sample_data = x[sample_idx][topic_mask[sample_idx]]\n",
    "                boot_means[b] = (\n",
    "                    np.mean(sample_data) if sample_data.size > 0 else np.nan\n",
    "                )\n",
    "\n",
    "            mean_ci_lower = np.nanpercentile(boot_means, 100 * alpha / 2)\n",
    "            mean_ci_upper = np.nanpercentile(boot_means, 100 * (1 - alpha / 2))\n",
    "            boot_desc_means_dict[(var, lvl)] = boot_means\n",
    "            rows.append({\n",
    "                \"variable\": var,\n",
    "                \"topic\": lvl,\n",
    "                \"mean\": mean,\n",
    "                \"mean_ci_lower\": mean_ci_lower,\n",
    "                \"mean_ci_upper\": mean_ci_upper,\n",
    "                \"std\": std\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e805b7",
   "metadata": {},
   "source": [
    "Summarize Testings with Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69d3d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal_wallis_bootstrap():\n",
    "\n",
    "    test_rows = []\n",
    "    for dv in emotions_p:\n",
    "\n",
    "        for iv_emo in emotions_a:\n",
    "            stats = emotion_parallel(dv, iv_emo)\n",
    "            signif_label = \"yes\" if stats[\"epsilon2_ci_lower\"] > 0 else \"no\"\n",
    "            test_rows.append({\n",
    "                \"criterion\": dv,\n",
    "                \"predictor\": iv_emo,\n",
    "                \"type\": \"emotion\",\n",
    "                \"signif_label\": signif_label,\n",
    "                **stats\n",
    "            })\n",
    "\n",
    "        stats = topic_parallel(dv)\n",
    "        signif_label = \"yes\" if stats[\"epsilon2_ci_lower\"] > 0 else \"no\"\n",
    "        test_rows.append({\n",
    "            \"criterion\": dv,\n",
    "            \"predictor\": \"NewsroomTopic\",\n",
    "            \"type\": \"NewsroomTopic\",\n",
    "            \"signif_label\": signif_label,\n",
    "            **stats\n",
    "        })\n",
    "\n",
    "    test_df = pd.DataFrame(test_rows)\n",
    "    desc_df = descriptive_stats()\n",
    "\n",
    "    return test_df, desc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3496e",
   "metadata": {},
   "source": [
    "# Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce77232",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats, desc_stats = kruskal_wallis_bootstrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4885e5d",
   "metadata": {},
   "source": [
    "Visualize Bootstrap Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d921116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bootstrap_distribution(stat_type, criterion=None, predictor=None, variable=None, topic=None):\n",
    "    \n",
    "    if stat_type in [\"H\", \"epsilon\", \"p\"]:\n",
    "        if criterion is None or predictor is None:\n",
    "            raise ValueError(\"criterion and predictor must be provided for Kruskal-Wallis stats\")\n",
    "        elif stat_type == \"epsilon\":\n",
    "            data = boot_epsilon_dict.get((criterion, predictor), [])\n",
    "            title = f\"EpsilonÂ² distribution for {criterion} ~ {predictor}\"\n",
    "        else:\n",
    "            data = boot_pvalues_dict.get((criterion, predictor), [])\n",
    "            title = f\"p-value distribution for {criterion} ~ {predictor}\"\n",
    "    elif stat_type in [\"mean\", \"std\"]:\n",
    "        if variable is None or topic is None:\n",
    "            raise ValueError(\"variable and topic must be provided for descriptives\")\n",
    "        if stat_type == \"mean\":\n",
    "            data = boot_desc_means_dict.get((variable, topic), [])\n",
    "            title = f\"Bootstrap means for {variable} in topic {topic}\"\n",
    "        else:\n",
    "            data = boot_desc_stds_dict.get((variable, topic), [])\n",
    "            title = f\"Bootstrap stds for {variable} in topic {topic}\"\n",
    "    else:\n",
    "        raise ValueError(\"stat_type must be one of H, epsilon, p, mean, std\")\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"No bootstrap data found for the given inputs.\")\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=data,\n",
    "        nbinsx=50,\n",
    "        histnorm='probability density',\n",
    "        marker_color='lightblue',\n",
    "        opacity=0.75\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=stat_type,\n",
    "        yaxis_title=\"Density\",\n",
    "        template=\"plotly_white\",\n",
    "        bargap=0.2\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd62e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats: epsilon, p, mean\n",
    "plot_bootstrap_distribution(stat_type=\"epsilon\", criterion=\"Anger_P\", predictor=\"Anger_A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c1f85",
   "metadata": {},
   "source": [
    "Save test_stats as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_stats.to_csv('test_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4486df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#desc_stats.to_csv('descriptive_stats.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
